{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uppercaveman/chatglm3-6b-model-quantization/blob/main/chatglm3-6b_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6op5vlm2dq"
      },
      "source": [
        "### 从 HuggingFace 下载 chatglm3-6b 模型\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_mI6KtJl4zC",
        "outputId": "bc305250-3277-4d4a-e95c-82b46a4cbe95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chatglm3-6b'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 109 (delta 4), reused 0 (delta 0), pack-reused 90\u001b[K\n",
            "Receiving objects: 100% (109/109), 59.26 KiB | 11.85 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "Filtering content: 100% (15/15), 23.26 GiB | 47.93 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# 从 HuggingFace 下载 chatglm3-6b 模型\n",
        "!git clone https://huggingface.co/THUDM/chatglm3-6b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4s2UsfZqHfG"
      },
      "source": [
        "### 从 Github 下载模型量化工具"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdnWWob0qTcG",
        "outputId": "edcbd5a2-1535-4088-9600-353c508bc3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chatglm.cpp'...\n",
            "remote: Enumerating objects: 596, done.\u001b[K\n",
            "remote: Counting objects: 100% (319/319), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 596 (delta 240), reused 180 (delta 150), pack-reused 277\u001b[K\n",
            "Receiving objects: 100% (596/596), 1.45 MiB | 7.23 MiB/s, done.\n",
            "Resolving deltas: 100% (345/345), done.\n",
            "Submodule 'third_party/ggml' (https://github.com/ggerganov/ggml.git) registered for path 'third_party/ggml'\n",
            "Submodule 'third_party/pybind11' (https://github.com/pybind/pybind11.git) registered for path 'third_party/pybind11'\n",
            "Submodule 'third_party/sentencepiece' (https://github.com/google/sentencepiece.git) registered for path 'third_party/sentencepiece'\n",
            "Cloning into '/content/chatglm.cpp/third_party/ggml'...\n",
            "remote: Enumerating objects: 6032, done.        \n",
            "remote: Counting objects: 100% (2361/2361), done.        \n",
            "remote: Compressing objects: 100% (190/190), done.        \n",
            "remote: Total 6032 (delta 2213), reused 2206 (delta 2167), pack-reused 3671        \n",
            "Receiving objects: 100% (6032/6032), 7.11 MiB | 18.57 MiB/s, done.\n",
            "Resolving deltas: 100% (3771/3771), done.\n",
            "Cloning into '/content/chatglm.cpp/third_party/pybind11'...\n",
            "remote: Enumerating objects: 27548, done.        \n",
            "remote: Counting objects: 100% (299/299), done.        \n",
            "remote: Compressing objects: 100% (129/129), done.        \n",
            "remote: Total 27548 (delta 176), reused 237 (delta 148), pack-reused 27249        \n",
            "Receiving objects: 100% (27548/27548), 10.51 MiB | 15.72 MiB/s, done.\n",
            "Resolving deltas: 100% (19453/19453), done.\n",
            "Cloning into '/content/chatglm.cpp/third_party/sentencepiece'...\n",
            "remote: Enumerating objects: 5065, done.        \n",
            "remote: Counting objects: 100% (2097/2097), done.        \n",
            "remote: Compressing objects: 100% (315/315), done.        \n",
            "remote: Total 5065 (delta 1840), reused 1852 (delta 1771), pack-reused 2968        \n",
            "Receiving objects: 100% (5065/5065), 26.79 MiB | 17.89 MiB/s, done.\n",
            "Resolving deltas: 100% (3493/3493), done.\n",
            "Submodule path 'third_party/ggml': checked out '6549d12f2e3176050040a86334f17c001e170f13'\n",
            "Submodule path 'third_party/pybind11': checked out '8b03ffa7c06cd9c8a38297b1c8923695d1ff1b07'\n",
            "Submodule path 'third_party/sentencepiece': checked out '635fe8423a249b6e081aacd290d8aef7476c6a28'\n"
          ]
        }
      ],
      "source": [
        "# 从 Github 下载模型量化工具\n",
        "!git clone --recursive https://github.com/li-plus/chatglm.cpp.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uofAluWhqpo7"
      },
      "source": [
        "### 安装项目依赖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOGwh_alrOFI",
        "outputId": "dafaf340-85f7-46b2-c314-dfbb7fe53cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 安装项目依赖\n",
        "!python3 -m pip install -U pip\n",
        "!python3 -m pip install torch tabulate tqdm transformers accelerate sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwdv7DKtryP1"
      },
      "source": [
        "### 使用covert.py脚本来进行量化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J63fhiKsEbh",
        "outputId": "986e6e09-c8ef-41d7-cb41-4934d2ddf80e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 7/7 [00:01<00:00,  4.06it/s]\n",
            "Processing model states: 100% 199/199 [04:05<00:00,  1.24s/it]\n",
            "+---------------------------------------------------------------------+---------------------------+---------+\n",
            "| name                                                                | shape                     | dtype   |\n",
            "|---------------------------------------------------------------------+---------------------------+---------|\n",
            "| transformer.embedding.word_embeddings.weight                        | torch.Size([65024, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.0.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.0.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.0.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.0.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.0.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.0.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.0.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.1.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.1.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.1.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.1.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.1.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.1.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.1.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.2.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.2.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.2.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.2.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.2.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.2.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.2.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.3.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.3.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.3.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.3.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.3.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.3.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.3.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.4.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.4.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.4.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.4.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.4.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.4.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.4.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.5.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.5.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.5.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.5.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.5.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.5.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.5.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.6.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.6.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.6.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.6.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.6.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.6.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.6.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.7.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.7.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.7.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.7.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.7.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.7.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.7.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.8.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.8.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.8.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.8.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.8.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.8.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.8.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.9.input_layernorm.weight                 | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.9.self_attention.query_key_value.weight  | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.9.self_attention.query_key_value.bias    | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.9.self_attention.dense.weight            | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.9.post_attention_layernorm.weight        | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.9.mlp.dense_h_to_4h.weight               | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.9.mlp.dense_4h_to_h.weight               | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.10.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.10.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.10.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.10.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.10.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.10.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.10.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.11.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.11.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.11.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.11.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.11.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.11.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.11.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.12.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.12.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.12.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.12.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.12.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.12.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.12.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.13.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.13.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.13.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.13.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.13.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.13.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.13.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.14.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.14.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.14.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.14.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.14.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.14.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.14.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.15.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.15.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.15.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.15.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.15.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.15.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.15.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.16.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.16.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.16.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.16.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.16.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.16.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.16.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.17.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.17.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.17.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.17.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.17.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.17.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.17.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.18.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.18.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.18.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.18.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.18.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.18.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.18.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.19.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.19.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.19.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.19.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.19.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.19.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.19.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.20.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.20.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.20.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.20.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.20.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.20.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.20.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.21.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.21.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.21.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.21.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.21.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.21.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.21.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.22.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.22.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.22.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.22.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.22.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.22.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.22.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.23.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.23.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.23.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.23.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.23.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.23.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.23.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.24.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.24.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.24.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.24.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.24.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.24.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.24.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.25.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.25.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.25.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.25.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.25.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.25.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.25.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.26.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.26.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.26.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.26.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.26.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.26.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.26.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.layers.27.input_layernorm.weight                | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.27.self_attention.query_key_value.weight | torch.Size([4608, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.27.self_attention.query_key_value.bias   | torch.Size([4608])        | F32     |\n",
            "| transformer.encoder.layers.27.self_attention.dense.weight           | torch.Size([4096, 4096])  | Q4_0    |\n",
            "| transformer.encoder.layers.27.post_attention_layernorm.weight       | torch.Size([4096])        | F32     |\n",
            "| transformer.encoder.layers.27.mlp.dense_h_to_4h.weight              | torch.Size([27392, 4096]) | Q4_0    |\n",
            "| transformer.encoder.layers.27.mlp.dense_4h_to_h.weight              | torch.Size([4096, 13696]) | Q4_0    |\n",
            "| transformer.encoder.final_layernorm.weight                          | torch.Size([4096])        | F32     |\n",
            "| transformer.output_layer.weight                                     | torch.Size([65024, 4096]) | Q4_0    |\n",
            "+---------------------------------------------------------------------+---------------------------+---------+\n",
            "GGML model saved to chatglm-ggml.bin\n"
          ]
        }
      ],
      "source": [
        "# 使用covert.py脚本来进行量化\n",
        "!python3 chatglm.cpp/chatglm_cpp/convert.py -i /content/chatglm3-6b -t q4_0 -o chatglm-ggml.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i5WdjpzveGp"
      },
      "source": [
        "### 保存量化模型到 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6WWS3JxLw4do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c0b7ec-14fa-417c-d48e-1c8de642db83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 挂载 Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wjPROZRgxEyj"
      },
      "outputs": [],
      "source": [
        "# 保存到 Google Drive\n",
        "!cp chatglm-ggml.bin /content/drive/MyDrive/chatglm-ggml.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 上传量化模型到 Huggingface"
      ],
      "metadata": {
        "id": "_SNaXgXRCKee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, HfApi\n",
        "login()\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/drive/MyDrive/chatglm-ggml.bin\",\n",
        "    path_in_repo=\"chatglm-ggml.bin\",\n",
        "    repo_id=\"chenbing0110/chatglm3-6b-ggml-q4_0\",\n",
        "    repo_type=\"model\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231,
          "referenced_widgets": [
            "9d03490c1980480e95526c962319f1fb",
            "54c35ca2f5ad4b78932c11ee63fdb7cd",
            "d570e4bc41ac4031965393f374c67722",
            "6e3f59dd0a544baaa289f25bbb45d83d",
            "57693383e01e487aa140b536df90be4c",
            "8678ef2267524b2f97ffb00af9c61d58",
            "51867e69e98247259c1c14b409b3902a",
            "a6ef17c1f72541479d04b8fa751fb860",
            "a73676f0df83436696a94dd61f44c0a5",
            "b1e0dd1b3f0f4948878f449beb0c8846",
            "9fb1917094a446bb8a8f55faf3a4af95",
            "925a85cd368b493fb562c4741ed0d82e",
            "6e0991716dfa4b1cb044922e712ebbd5",
            "672a9070bca842b086f2c6dd5db51f0a",
            "063b449363514b8d99b4873aae3dc08a",
            "afa3f86af0f44532b530c571d8d8f198",
            "18219d14bcbd4051be73a13a634e1b14",
            "25b27be66ab543d7ba37491410a277d1",
            "646d68214c5342cd948ba8d79152590d",
            "ad8aae0ae20a45b1b7b77968253490ec",
            "0df0e495049b445c8a9be3d7b1336e58",
            "c53d21a5901e4ab088d2c7fad62cc940",
            "76f4b23cb2e849abad18a35127bc0aad",
            "b3e0e571706a4ce987d5e236d0b3988c",
            "8b4c89783c244076ba7701a454cfd008",
            "6bacf5426bdc4328b4d3493c6f898760",
            "fed2923243fd421bbfb07137ea7529dd",
            "0cb1c03cd3684a219d15bd336ddf6e05",
            "eded945a825744efba0ded495e7a1f68",
            "2c4a7e2a55ed48d1a6071b4ffda12edc",
            "99665773311b4c8b86867d2c6e1ad719",
            "894977b5cff246488b51f3faf1e8fb6f",
            "4312896473144530873da96913c882e7",
            "58e6f44696be4a5a9b43d7103a2a3adb",
            "16ec0e9fdfaa4661bd41186308e9499f",
            "c6f465b9755540679cf8c6840704558a",
            "480efca09c434c7b840400182f62e367",
            "e1bb5ebf4cb64cf0bc9ee9eafb67d57a",
            "5680b009c8d34b51874714f3d1c8c605",
            "37558b1df3204e059c85b5860ab60626",
            "d658012df638474b89ce39c0b9a6a245",
            "6895334ea0cf40f4a21689d2d7a10b60",
            "200174f0eab94cb29f954a69473cfb52"
          ]
        },
        "id": "lGl0Wsx-CN8Y",
        "outputId": "2c406dcf-92e7-4302-aef9-d826a0925425"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d03490c1980480e95526c962319f1fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chatglm-ggml.bin:   0%|          | 0.00/3.51G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25b27be66ab543d7ba37491410a277d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/chenbing0110/chatglm3-6b-ggml-q4_0/commit/4186f85d674132c44ac1e7dfbfed0853ad829e3e', commit_message='Upload chatglm-ggml.bin with huggingface_hub', commit_description='', oid='4186f85d674132c44ac1e7dfbfed0853ad829e3e', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 源码编译运行量化模型"
      ],
      "metadata": {
        "id": "yJ7wko_7cPEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 编译 chatglm.cpp 的运行命令\n",
        "!cd chatglm.cpp && cmake -B build && cmake --build build -j --config Release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKeWyx9Kca2V",
        "outputId": "88cf0aa7-1db2-4429-b3e0-a5df22bcf3db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[0mCMake Deprecation Warning at third_party/ggml/CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- x86 detected\n",
            "-- Linux detected\n",
            "\u001b[0mCMake Deprecation Warning at third_party/sentencepiece/CMakeLists.txt:15 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- VERSION: 0.2.00\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Configuring done (1.9s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/chatglm.cpp/build\n",
            "[  1%] \u001b[32mBuilding C object third_party/ggml/src/CMakeFiles/ggml.dir/ggml.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/bytestream.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object third_party/ggml/src/CMakeFiles/ggml.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arena.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arenastring.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/common.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/unicode_script.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/coded_stream.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding C object third_party/ggml/src/CMakeFiles/ggml.dir/ggml-backend.c.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/trainer_factory.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/builder.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/trainer_interface.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/unigram_model_trainer.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/word_model_trainer.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/extension_set.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_enum_util.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/char_model_trainer.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/bpe_model_trainer.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/sentencepiece_trainer.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece_train-static.dir/pretokenizer_for_training.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/int128.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/io_win32.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/message_lite.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/parse_context.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/repeated_field.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/status.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/statusor.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringpiece.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringprintf.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/strutil.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/time.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece.pb.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece_model.pb.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/char_model.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/bpe_model.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/filesystem.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/model_interface.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/error.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/normalizer.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/model_factory.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/sentencepiece_processor.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/util.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/unigram_model.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/word_model.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/flags/flag.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/usr/include/string.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/port.h:39\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/macros.h:34\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/common.h:46\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/message_lite.h:45\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/third_party/protobuf-lite/message_lite.cc:36\u001b[m\u001b[K:\n",
            "In function ‘\u001b[01m\u001b[Kvoid* memcpy(void*, const void*, size_t)\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[Kgoogle::protobuf::uint8* google::protobuf::io::EpsCopyOutputStream::WriteRaw(const void*, int, google::protobuf::uint8*)\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/io/coded_stream.h:699:16\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvirtual google::protobuf::uint8* google::protobuf::internal::ImplicitWeakMessage::_InternalSerialize(google::protobuf::uint8*, google::protobuf::io::EpsCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/implicit_weak_message.h:85:28\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kbool google::protobuf::MessageLite::SerializePartialToZeroCopyStream(google::protobuf::io::ZeroCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/chatglm.cpp/third_party/sentencepiece/third_party/protobuf-lite/message_lite.cc:419:30\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/string_fortified.h:29:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid* __builtin___memcpy_chk(void*, const void*, long unsigned int, long unsigned int)\u001b[m\u001b[K’ specified size between 18446744071562067968 and 18446744073709551615 exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wstringop-overflow=\u0007-Wstringop-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   29 |   return \u001b[01;35m\u001b[K__builtin___memcpy_chk (__dest, __src, __len,\u001b[m\u001b[K\n",
            "      |          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   30 | \u001b[01;35m\u001b[K                                 __glibc_objsize0 (__dest))\u001b[m\u001b[K;\n",
            "      |                                  \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX static library ../../../lib/libsentencepiece.a\u001b[0m\n",
            "[ 75%] Built target sentencepiece-static\n",
            "[ 76%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/spm_decode.dir/spm_decode_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/spm_encode.dir/spm_encode_main.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/spm_export_vocab.dir/spm_export_vocab_main.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking C shared library ../../../lib/libggml.so\u001b[0m\n",
            "[ 80%] Built target ggml\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/chatglm.dir/chatglm.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../../bin/spm_export_vocab\u001b[0m\n",
            "[ 83%] Built target spm_export_vocab\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../../bin/spm_decode\u001b[0m\n",
            "[ 84%] Built target spm_decode\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../../../bin/spm_encode\u001b[0m\n",
            "[ 86%] Built target spm_encode\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX static library ../../../lib/libsentencepiece_train.a\u001b[0m\n",
            "[ 87%] Built target sentencepiece_train-static\n",
            "[ 88%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/spm_normalize.dir/spm_normalize_main.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object third_party/sentencepiece/src/CMakeFiles/spm_train.dir/spm_train_main.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX executable ../../../bin/spm_normalize\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../../bin/spm_train\u001b[0m\n",
            "[ 93%] Built target spm_normalize\n",
            "[ 93%] Built target spm_train\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX static library lib/libchatglm.a\u001b[0m\n",
            "[ 94%] Built target chatglm\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/main.dir/main.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/perplexity.dir/tests/perplexity.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable bin/perplexity\u001b[0m\n",
            "[ 98%] Built target perplexity\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable bin/main\u001b[0m\n",
            "[100%] Built target main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 编译完成后在 chatglm.cpp 目录下会生成一个build目录，编译完成后的命令就放在这个目录下，然后我们就可以运行模型了，运行命令如下：\n",
        "!chatglm.cpp/build/bin/main -m /content/drive/MyDrive/chatglm-ggml.bin -p \"你好\"\n",
        "# 上面的命令中，-m参数带上量化模型的地址，-p参数是输入的提示词，然后我们可以看到 LLM 的输出结果，跟运行原模型的结果是一样的。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKCq7UZ2eAqJ",
        "outputId": "1cca3b1d-9e59-4cc9-d4a3-3ddfeac73264"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们还可以通过-i参数来发起交互式对话，命令如下：\n",
        "!chatglm.cpp/build/bin/main -m /content/drive/MyDrive/chatglm-ggml.bin -i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y4zFIkEe0Ww",
        "outputId": "67f485c5-e9b6-42a2-f4b6-d612e4164cce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ________          __  ________    __  ___                 \n",
            "   / ____/ /_  ____ _/ /_/ ____/ /   /  |/  /_________  ____  \n",
            "  / /   / __ \\/ __ `/ __/ / __/ /   / /|_/ // ___/ __ \\/ __ \\ \n",
            " / /___/ / / / /_/ / /_/ /_/ / /___/ /  / // /__/ /_/ / /_/ / \n",
            " \\____/_/ /_/\\__,_/\\__/\\____/_____/_/  /_(_)___/ .___/ .___/  \n",
            "                                              /_/   /_/       \n",
            "\n",
            "Welcome to ChatGLM.cpp! Ask whatever you want. Type 'clear' to clear context. Type 'stop' to exit.\n",
            "\n",
            "Prompt   > 你好\n",
            "ChatGLM3 > 你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\n",
            "Prompt   > 请介绍一下三星堆\n",
            "\n",
            "ChatGLM3 > 三星堆，位于中国四川省广汉市，是一处著名的古文明遗址，距今约3000-5000年。1986年，三星堆遗址被发现了无障碍 Knife夫 struct workds，成了c construction. confidentiablen的现代化三星堆文明，也是考古学上目前世界范围occurrence found o力度最大的陶器时代文化之一。\n",
            "\n",
            "三星堆遗址的交易 relation 关系 include有协议 many types of objects, such as ceramics,料器, tools and weapons, which provide clues about the culture and technology of the ancient civilization. The find of a large number of勾股定理治朴作玉挂件和金戴冠及联升 hall,分烈是鸭对鸭 void 作玉,少祖传 Ace_5000 and 和其他gradable 文化的影响。\n",
            "\n",
            "目前，三星堆遗址的考古发掘仍在进行中， scientists 们 continues努力揭示这个古文明的奥秘。\n",
            "Prompt   > Prompt   > ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用 Python 包运行量化模型"
      ],
      "metadata": {
        "id": "QlGV69Cxhi8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chatglm.cpp 还提供了 Python 包，使用该工具包我们也可以运行量化后的模型，首先安装 Python 依赖包，命令如下：\n",
        "!pip install -U chatglm-cpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOiDaxxah_w4",
        "outputId": "751bd9b7-d902-4b22-a472-22fdd1dfdc3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chatglm-cpp\n",
            "  Downloading chatglm-cpp-0.3.1.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: chatglm-cpp\n",
            "  Building wheel for chatglm-cpp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chatglm-cpp: filename=chatglm_cpp-0.3.1-cp310-cp310-linux_x86_64.whl size=825122 sha256=5b88e463d65e2955fa269576e06b03094fdf19c136aac8481fabe75ca7bfeb39\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/d5/b5/013d7e9b0893e485df77a9eabb231d54a0e803438550f0d75c\n",
            "Successfully built chatglm-cpp\n",
            "Installing collected packages: chatglm-cpp\n",
            "Successfully installed chatglm-cpp-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 Python 代码来运行量化模型\n",
        "import chatglm_cpp\n",
        "\n",
        "pipeline = chatglm_cpp.Pipeline(\"/content/drive/MyDrive/chatglm-ggml.bin\")\n",
        "pipeline.chat([chatglm_cpp.ChatMessage(role=\"user\", content=\"你好\")])\n",
        "\n",
        "# 结果显示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yBayAKHj11k",
        "outputId": "5f61fc60-c44c-4678-8a72-e501399249ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatMessage(role=\"assistant\", content=\"你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\", tool_calls=[])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 命令行执行"
      ],
      "metadata": {
        "id": "qetF7vp7ky8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 Python 脚本运行量化模型，脚本文件在 chatglm.cpp 项目下的 examples 目录中，命令如下：\n",
        "!python chatglm.cpp/examples/cli_demo.py -m /content/drive/MyDrive/chatglm-ggml.bin -p 你好"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8fj5YUGk2yC",
        "outputId": "51faffa0-1a2d-44d5-fe41-2ecf012d92d2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 部署 Web 服务 - Gradio"
      ],
      "metadata": {
        "id": "EhdIS_KulcAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们可以将量化后的模型部署为 Web 服务，这样就可以在浏览器中来调用模型，这里我们使用 chatglm.cpp 提供的 Web 服务脚本来部署模型。\n",
        "# 安装 Gradio 依赖，命令如下：\n",
        "!python3 -m pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZczJ8Onlgye",
        "outputId": "cb21cbee-c8af-44d9-f84b-163fe3b00133"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.16.0-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.8.1 (from gradio)\n",
            "  Downloading gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.6.0-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.1.7 (from gradio)\n",
            "  Downloading ruff-0.1.15-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.16.1 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.36.0,>=0.35.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->gradio)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=34bbea7038f65a075ac74e672a32703b11190c30a5ebd2f15c2961336eb762fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.14\n",
            "    Uninstalling pydantic-1.10.14:\n",
            "      Successfully uninstalled pydantic-1.10.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.109.0 ffmpy-0.3.1 gradio-4.16.0 gradio-client-0.8.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 orjson-3.9.12 pydantic-2.6.0 pydantic-core-2.16.1 pydub-0.25.1 python-multipart-0.0.6 ruff-0.1.15 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.35.1 tomlkit-0.12.0 typing-extensions-4.9.0 uvicorn-0.27.0.post1 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 再修改 Web 服务脚本 chatglm.cpp/examples/web_demo.py，将Share属性改为True，这样可以在服务器外访问 Web 服务.\n",
        "# 启动 Web 服务，命令如下：\n",
        "!python3 chatglm.cpp/examples/web_demo.py -m /content/drive/MyDrive/chatglm-ggml.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUHwdDo2mA3_",
        "outputId": "ab4ef097-a350-41eb-c699-f77aa0a5ed44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://e98c338c9d8d637f50.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2233, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/chatglm.cpp/examples/web_demo.py\", line 101, in <module>\n",
            "    demo.queue().launch(share=True, inbrowser=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2140, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2237, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 76, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e98c338c9d8d637f50.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 部署 Web 服务 - Streamlit"
      ],
      "metadata": {
        "id": "gZsY_kJpp8P_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装 Streamlit 依赖，命令如下：\n",
        "!python3 -m pip install streamlit jupyter_client ipython ipykernel\n",
        "!ipython kernel install --name chatglm3-demo --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY3lQeNAqCvJ",
        "outputId": "b338345d-6d62-4811-b0f7-abd823ec4e7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.30.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter_client in /usr/local/lib/python3.10/dist-packages (6.1.12)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.9.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from jupyter_client) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_client) (5.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter_client) (23.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter_client) (4.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, jedi, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.41 jedi-0.19.1 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.30.0 validators-0.22.0 watchdog-3.0.0\n",
            "Installed kernelspec chatglm3-demo in /root/.local/share/jupyter/kernels/chatglm3-demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "再修改综合服务的脚本 chatglm.cpp/examples/chatglm3_demo.py，将模型的地址改为量化模型的地址，改动如下：\n",
        "\n",
        "-MODEL_PATH = Path(__file__).resolve().parent.parent / \"chatglm3-ggml.bin\"\n",
        "\n",
        "+MODEL_PATH = \"/content/drive/MyDrive/chatglm-ggml.bin\"\n"
      ],
      "metadata": {
        "id": "aLFAMfYGqeoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们还需要将 Colab 服务器中的 Web 服务代理到公网，需要安装 CloudFlare 的反向代理，这样我们才可以在服务器外访问该 Web 服务，命令如下：\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLzf8fPVqhKH",
        "outputId": "98377d56-443a-42a6-930e-4ec18f998de3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-31 08:45:14--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2024.1.5/cloudflared-linux-amd64 [following]\n",
            "--2024-01-31 08:45:15--  https://github.com/cloudflare/cloudflared/releases/download/2024.1.5/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/3e1a9578-ca20-4ec0-aead-3080c5647407?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240131%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240131T084515Z&X-Amz-Expires=300&X-Amz-Signature=f4b8ce1a32ece59c5bcbb920c7ff5b872dd11e3aa25017d9a63d031a437951f3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-01-31 08:45:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/3e1a9578-ca20-4ec0-aead-3080c5647407?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240131%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240131T084515Z&X-Amz-Expires=300&X-Amz-Signature=f4b8ce1a32ece59c5bcbb920c7ff5b872dd11e3aa25017d9a63d031a437951f3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36501267 (35M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  34.81M   152MB/s    in 0.2s    \n",
            "\n",
            "2024-01-31 08:45:15 (152 MB/s) - ‘cloudflared-linux-amd64’ saved [36501267/36501267]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 最后启动 Streamlit Web 服务和代理服务，命令如下：\n",
        "!streamlit run chatglm.cpp/examples/chatglm3_demo.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "zq8TErWnr_WQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 启动代理服务\n",
        "!grep -o 'https://.*\\.trycloudflare.com' nohup.out | head -n 1 | xargs -I {} echo \"Your tunnel url {}\"\n",
        "!nohup /content/cloudflared-linux-amd64 tunnel --url http://localhost:8501 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_N_2niYs1-z",
        "outputId": "50fbcccb-ed46-4cfb-923f-895188289bf1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your tunnel url https://proceed-statutory-affairs-notices.trycloudflare.com\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 部署 API 服务"
      ],
      "metadata": {
        "id": "4gx_wX4Yus7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们还可以将量化后的模型部署为 API 服务，chatglm.cpp 的 Python 包提供了启动 API 服务的功能，该 API 适配 OpenAI API。\n",
        "# 安装 chatglm.cpp 的 API 包，命令如下：\n",
        "!pip install -U 'chatglm-cpp[api]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdLQK2mcuv-R",
        "outputId": "70cd69b8-16db-46f3-8eb7-3e26fd985e4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chatglm-cpp[api] in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: fastapi[all] in /usr/local/lib/python3.10/dist-packages (from chatglm-cpp[api]) (0.109.0)\n",
            "Collecting sse-starlette (from chatglm-cpp[api])\n",
            "  Downloading sse_starlette-2.0.0-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (2.6.0)\n",
            "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (0.35.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (4.9.0)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading email_validator-2.1.0.post1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (0.26.0)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (2.1.2)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (3.1.3)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (3.9.12)\n",
            "Collecting pydantic-extra-types>=2.0.0 (from fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading pydantic_extra_types-2.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting pydantic-settings>=2.0.0 (from fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading pydantic_settings-2.1.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (0.0.6)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (6.0.1)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: uvicorn[standard]>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[all]->chatglm-cpp[api]) (0.27.0.post1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from sse-starlette->chatglm-cpp[api]) (3.7.1)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading dnspython-2.5.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.4/305.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator>=2.0.0->fastapi[all]->chatglm-cpp[api]) (3.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[all]->chatglm-cpp[api]) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[all]->chatglm-cpp[api]) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[all]->chatglm-cpp[api]) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[all]->chatglm-cpp[api]) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi[all]->chatglm-cpp[api]) (2.1.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]->chatglm-cpp[api]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]->chatglm-cpp[api]) (2.16.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.0->fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->sse-starlette->chatglm-cpp[api]) (1.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi[all]->chatglm-cpp[api]) (8.1.7)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi[all]->chatglm-cpp[api])\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi[all]->chatglm-cpp[api]) (11.0.3)\n",
            "Installing collected packages: uvloop, ujson, python-dotenv, httptools, dnspython, watchfiles, email-validator, sse-starlette, pydantic-settings, pydantic-extra-types\n",
            "Successfully installed dnspython-2.5.0 email-validator-2.1.0.post1 httptools-0.6.1 pydantic-extra-types-2.5.0 pydantic-settings-2.1.0 python-dotenv-1.0.1 sse-starlette-2.0.0 ujson-5.9.0 uvloop-0.19.0 watchfiles-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 然后启动 API 服务，命令如下：\n",
        "!MODEL=/content/drive/MyDrive/chatglm-ggml.bin uvicorn chatglm_cpp.openai_api:app --host 127.0.0.1 --port 8000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAZdL8VRxhGe",
        "outputId": "b1c2c9c7-b5c7-4d91-d0e0-0c533147a1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m26844\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 环境变量是量化模型的地址，然后我们使用curl命令来验证一下 API 服务是否正常，命令如下：\n",
        "!curl http://127.0.0.1:8000/v1/chat/completions -H 'Content-Type: application/json' -d '{\"messages\": [{\"role\": \"user\", \"content\": \"请介绍一下三星堆\"}]}'\n",
        "# 可以看到 API 返回结果的数据结构跟 OpenAI API 的数据结构是一样的。"
      ],
      "metadata": {
        "id": "T2rnU8wFxyvc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4b6op5vlm2dq",
        "E4s2UsfZqHfG",
        "uofAluWhqpo7",
        "mwdv7DKtryP1",
        "3i5WdjpzveGp",
        "_SNaXgXRCKee",
        "yJ7wko_7cPEA",
        "QlGV69Cxhi8A",
        "qetF7vp7ky8t",
        "EhdIS_KulcAb"
      ],
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1bl9eRksY8bpcA6Lfz3O6SfzC9xKmGaqh",
      "authorship_tag": "ABX9TyNfcAXgAiZyKg7Rae38FMNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d03490c1980480e95526c962319f1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_894977b5cff246488b51f3faf1e8fb6f",
              "IPY_MODEL_4312896473144530873da96913c882e7",
              "IPY_MODEL_58e6f44696be4a5a9b43d7103a2a3adb",
              "IPY_MODEL_16ec0e9fdfaa4661bd41186308e9499f"
            ],
            "layout": "IPY_MODEL_51867e69e98247259c1c14b409b3902a"
          }
        },
        "54c35ca2f5ad4b78932c11ee63fdb7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ef17c1f72541479d04b8fa751fb860",
            "placeholder": "​",
            "style": "IPY_MODEL_a73676f0df83436696a94dd61f44c0a5",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "d570e4bc41ac4031965393f374c67722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b1e0dd1b3f0f4948878f449beb0c8846",
            "placeholder": "​",
            "style": "IPY_MODEL_9fb1917094a446bb8a8f55faf3a4af95",
            "value": ""
          }
        },
        "6e3f59dd0a544baaa289f25bbb45d83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_925a85cd368b493fb562c4741ed0d82e",
            "style": "IPY_MODEL_6e0991716dfa4b1cb044922e712ebbd5",
            "value": true
          }
        },
        "57693383e01e487aa140b536df90be4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_672a9070bca842b086f2c6dd5db51f0a",
            "style": "IPY_MODEL_063b449363514b8d99b4873aae3dc08a",
            "tooltip": ""
          }
        },
        "8678ef2267524b2f97ffb00af9c61d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa3f86af0f44532b530c571d8d8f198",
            "placeholder": "​",
            "style": "IPY_MODEL_18219d14bcbd4051be73a13a634e1b14",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "51867e69e98247259c1c14b409b3902a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a6ef17c1f72541479d04b8fa751fb860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73676f0df83436696a94dd61f44c0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1e0dd1b3f0f4948878f449beb0c8846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb1917094a446bb8a8f55faf3a4af95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "925a85cd368b493fb562c4741ed0d82e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0991716dfa4b1cb044922e712ebbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "672a9070bca842b086f2c6dd5db51f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063b449363514b8d99b4873aae3dc08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "afa3f86af0f44532b530c571d8d8f198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18219d14bcbd4051be73a13a634e1b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25b27be66ab543d7ba37491410a277d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_646d68214c5342cd948ba8d79152590d",
              "IPY_MODEL_ad8aae0ae20a45b1b7b77968253490ec",
              "IPY_MODEL_0df0e495049b445c8a9be3d7b1336e58"
            ],
            "layout": "IPY_MODEL_c53d21a5901e4ab088d2c7fad62cc940"
          }
        },
        "646d68214c5342cd948ba8d79152590d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f4b23cb2e849abad18a35127bc0aad",
            "placeholder": "​",
            "style": "IPY_MODEL_b3e0e571706a4ce987d5e236d0b3988c",
            "value": "chatglm-ggml.bin: 100%"
          }
        },
        "ad8aae0ae20a45b1b7b77968253490ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4c89783c244076ba7701a454cfd008",
            "max": 3514297136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bacf5426bdc4328b4d3493c6f898760",
            "value": 3514297136
          }
        },
        "0df0e495049b445c8a9be3d7b1336e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fed2923243fd421bbfb07137ea7529dd",
            "placeholder": "​",
            "style": "IPY_MODEL_0cb1c03cd3684a219d15bd336ddf6e05",
            "value": " 3.51G/3.51G [01:35&lt;00:00, 41.6MB/s]"
          }
        },
        "c53d21a5901e4ab088d2c7fad62cc940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f4b23cb2e849abad18a35127bc0aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e0e571706a4ce987d5e236d0b3988c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4c89783c244076ba7701a454cfd008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bacf5426bdc4328b4d3493c6f898760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fed2923243fd421bbfb07137ea7529dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb1c03cd3684a219d15bd336ddf6e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eded945a825744efba0ded495e7a1f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4a7e2a55ed48d1a6071b4ffda12edc",
            "placeholder": "​",
            "style": "IPY_MODEL_99665773311b4c8b86867d2c6e1ad719",
            "value": "Connecting..."
          }
        },
        "2c4a7e2a55ed48d1a6071b4ffda12edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99665773311b4c8b86867d2c6e1ad719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "894977b5cff246488b51f3faf1e8fb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f465b9755540679cf8c6840704558a",
            "placeholder": "​",
            "style": "IPY_MODEL_480efca09c434c7b840400182f62e367",
            "value": "Token is valid (permission: write)."
          }
        },
        "4312896473144530873da96913c882e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1bb5ebf4cb64cf0bc9ee9eafb67d57a",
            "placeholder": "​",
            "style": "IPY_MODEL_5680b009c8d34b51874714f3d1c8c605",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "58e6f44696be4a5a9b43d7103a2a3adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37558b1df3204e059c85b5860ab60626",
            "placeholder": "​",
            "style": "IPY_MODEL_d658012df638474b89ce39c0b9a6a245",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "16ec0e9fdfaa4661bd41186308e9499f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6895334ea0cf40f4a21689d2d7a10b60",
            "placeholder": "​",
            "style": "IPY_MODEL_200174f0eab94cb29f954a69473cfb52",
            "value": "Login successful"
          }
        },
        "c6f465b9755540679cf8c6840704558a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480efca09c434c7b840400182f62e367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1bb5ebf4cb64cf0bc9ee9eafb67d57a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5680b009c8d34b51874714f3d1c8c605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37558b1df3204e059c85b5860ab60626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d658012df638474b89ce39c0b9a6a245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6895334ea0cf40f4a21689d2d7a10b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200174f0eab94cb29f954a69473cfb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}